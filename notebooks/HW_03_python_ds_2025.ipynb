{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca0353b",
   "metadata": {
    "id": "aca0353b"
   },
   "source": [
    "# Домашнее задание 3. Парсинг, Git и тестирование на Python\n",
    "\n",
    "**Цели задания:**\n",
    "\n",
    "* Освоить базовые подходы к web-scraping с библиотеками `requests` и `BeautisulSoup`: навигация по страницам, извлечение HTML-элементов, парсинг.\n",
    "* Научиться автоматизировать задачи с использованием библиотеки `schedule`.\n",
    "* Попрактиковаться в использовании Git и оформлении проектов на GitHub.\n",
    "* Написать и запустить простые юнит-тесты с использованием `pytest`.\n",
    "\n",
    "\n",
    "В этом домашнем задании вы разработаете систему для автоматического сбора данных о книгах с сайта [Books to Scrape](http://books.toscrape.com). Нужно реализовать функции для парсинга всех страниц сайта, извлечения информации о книгах, автоматического ежедневного запуска задачи и сохранения результата.\n",
    "\n",
    "Важной частью задания станет оформление проекта: вы создадите репозиторий на GitHub, оформите `README.md`, добавите артефакты (код, данные, отчеты) и напишете базовые тесты на `pytest`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "K3JMV0qwmA_q",
   "metadata": {
    "id": "K3JMV0qwmA_q"
   },
   "outputs": [],
   "source": [
    "! pip install -q schedule pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873d4904",
   "metadata": {
    "id": "873d4904"
   },
   "outputs": [],
   "source": [
    "# Библиотеки, которые могут вам понадобиться\n",
    "# При необходимости расширяйте список\n",
    "import time\n",
    "import requests\n",
    "import schedule\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unTvsWaegHdj",
   "metadata": {
    "id": "unTvsWaegHdj"
   },
   "source": [
    "## Задание 1. Сбор данных об одной книге (20 баллов)\n",
    "\n",
    "В этом задании мы начнем подготовку скрипта для парсинга информации о книгах со страниц каталога сайта [Books to Scrape](https://books.toscrape.com/).\n",
    "\n",
    "Для начала реализуйте функцию `get_book_data`, которая будет получать данные о книге с одной страницы (например, с [этой](http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html)). Соберите всю информацию, включая название, цену, рейтинг, количество в наличии, описание и дополнительные характеристики из таблицы Product Information. Результат достаточно вернуть в виде словаря.\n",
    "\n",
    "**Не забывайте про соблюдение PEP-8** — помимо качественно написанного кода важно также документировать функции по стандарту:\n",
    "* кратко описать, что она делает и для чего нужна;\n",
    "* какие входные аргументы принимает, какого они типа и что означают по смыслу;\n",
    "* аналогично описать возвращаемые значения.\n",
    "\n",
    "*P. S. Состав, количество аргументов функции и тип возвращаемого значения можете менять как вам удобно. То, что написано ниже в шаблоне — лишь пример.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "UfD2vAjHkEoS",
   "metadata": {
    "id": "UfD2vAjHkEoS"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_book_data(book_url):\n",
    "    \"\"\"\n",
    "    Получает данные о книге с указанной страницы каталога Books to Scrape.\n",
    "    \n",
    "    Функция парсит HTML-страницу книги и извлекает всю основную информацию:\n",
    "    название, цену, рейтинг, количество в наличии, описание и дополнительные \n",
    "    характеристики из таблицы Product Information.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    book_url : str\n",
    "        URL-адрес страницы книги для парсинга\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Словарь с данными о книге, содержащий следующие ключи:\n",
    "        - 'title': название книги (str)\n",
    "        - 'price': цена книги (str)\n",
    "        - 'rating': рейтинг книги (str)\n",
    "        - 'stock': количество в наличии (str)\n",
    "        - 'description': описание книги (str)\n",
    "        - 'upc': универсальный код товара (str)\n",
    "        - 'product_type': тип товара (str)\n",
    "        - 'price_excl_tax': цена без налога (str)\n",
    "        - 'price_incl_tax': цена с налогом (str)\n",
    "        - 'tax': сумма налога (str)\n",
    "        - 'availability': информация о наличии (str)\n",
    "        - 'number_of_reviews': количество отзывов (str)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(book_url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Название (с проверкой)\n",
    "        title_element = soup.find('h1')\n",
    "        title = title_element.text.strip() if title_element else \"Нет названия\"\n",
    "        \n",
    "        # Цена (с проверкой)\n",
    "        price_element = soup.find('p', class_='price_color')\n",
    "        price = price_element.text.strip() if price_element else \"Нет цены\"\n",
    "        \n",
    "        # Рейтинг (с проверкой)\n",
    "        rating_element = soup.find('p', class_='star-rating')\n",
    "        if rating_element and len(rating_element.get('class', [])) > 1:\n",
    "            rating = rating_element['class'][1]\n",
    "        else:\n",
    "            rating = \"No rating\"\n",
    "        \n",
    "        # В наличии (с проверкой)\n",
    "        stock_element = soup.find('p', class_='instock availability')\n",
    "        stock = \"0\"\n",
    "        if stock_element:\n",
    "            stock_text = stock_element.text\n",
    "            stock_match = re.search(r'\\((\\d+) available\\)', stock_text)\n",
    "            if stock_match:\n",
    "                stock = stock_match.group(1)\n",
    "        \n",
    "        # Описание (с проверкой)\n",
    "        description_element = soup.find('div', id='product_description')\n",
    "        description = \"Нет описания\"\n",
    "        if description_element:\n",
    "            description_sibling = description_element.find_next_sibling('p')\n",
    "            if description_sibling:\n",
    "                description = description_sibling.text.strip()\n",
    "        \n",
    "        # Таблица с дополнительной информацией (с проверкой)\n",
    "        product_info = {}\n",
    "        table = soup.find('table', class_='table table-striped')\n",
    "        if table:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                header_element = row.find('th')\n",
    "                value_element = row.find('td')\n",
    "                if header_element and value_element:\n",
    "                    header = header_element.text.strip()\n",
    "                    value = value_element.text.strip()\n",
    "                    product_info[header] = value\n",
    "        \n",
    "        book_data = {\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "            'rating': rating,\n",
    "            'stock': stock,\n",
    "            'description': description,\n",
    "            'upc': product_info.get('UPC', ''),\n",
    "            'product_type': product_info.get('Product Type', ''),\n",
    "            'price_excl_tax': product_info.get('Price (excl. tax)', ''),\n",
    "            'price_incl_tax': product_info.get('Price (incl. tax)', ''),\n",
    "            'tax': product_info.get('Tax', ''),\n",
    "            'availability': product_info.get('Availability', ''),\n",
    "            'number_of_reviews': product_info.get('Number of reviews', '')\n",
    "        }\n",
    "        \n",
    "        return book_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в get_book_data: {e}\")\n",
    "        return {\n",
    "            'title': f'Ошибка: {str(e)[:50]}',\n",
    "            'price': '0',\n",
    "            'rating': 'Zero',\n",
    "            'stock': '0',\n",
    "            'description': 'Ошибка загрузки',\n",
    "            'upc': '',\n",
    "            'product_type': '',\n",
    "            'price_excl_tax': '',\n",
    "            'price_incl_tax': '',\n",
    "            'tax': '',\n",
    "            'availability': '',\n",
    "            'number_of_reviews': ''\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moRSO9Itp1LT",
   "metadata": {
    "id": "moRSO9Itp1LT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'A Light in the Attic',\n",
       " 'price': '£51.77',\n",
       " 'rating': 'Three',\n",
       " 'stock': '22',\n",
       " 'description': \"It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love th It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love that Silverstein. Need proof of his genius? RockabyeRockabye baby, in the treetopDon't you know a treetopIs no safe place to rock?And who put you up there,And your cradle, too?Baby, I think someone down here'sGot it in for you. Shel, you never sounded so good. ...more\",\n",
       " 'upc': 'a897fe39b1053632',\n",
       " 'product_type': 'Books',\n",
       " 'price_excl_tax': '£51.77',\n",
       " 'price_incl_tax': '£51.77',\n",
       " 'tax': '£0.00',\n",
       " 'availability': 'In stock (22 available)',\n",
       " 'number_of_reviews': '0'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Используйте для самопроверки\n",
    "book_url = 'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'\n",
    "get_book_data(book_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u601Q4evosq6",
   "metadata": {
    "id": "u601Q4evosq6"
   },
   "source": [
    "## Задание 2. Сбор данных обо всех книгах (20 баллов)\n",
    "\n",
    "Создайте функцию `scrape_books`, которая будет проходиться по всем страницам из каталога (вида `http://books.toscrape.com/catalogue/page-{N}.html`) и осуществлять парсинг всех страниц в цикле, используя ранее написанную `get_book_data`.\n",
    "\n",
    "Добавьте аргумент-флаг, который будет отвечать за сохранение результата в файл: если он будет равен `True`, то информация сохранится в ту же папку в файл `books_data.txt`; иначе шаг сохранения будет пропущен.\n",
    "\n",
    "**Также не забывайте про соблюдение PEP-8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "kk78l6oDkdxl",
   "metadata": {
    "id": "kk78l6oDkdxl"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def scrape_books(is_save=False):\n",
    "    \"\"\"\n",
    "        Парсит данные обо всех книгах со всех страниц каталога Books to Scrape.\n",
    "    \n",
    "    Функция последовательно проходит по всем страницам каталога, извлекает ссылки\n",
    "    на отдельные книги и собирает о них данные с помощью функции get_book_data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    is_save : bool, optional\n",
    "        Флаг сохранения результатов в файл. Если True, данные сохраняются\n",
    "        в файл books_data.txt в текущей папке. По умолчанию False.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict]\n",
    "        Список словарей, где каждый словарь содержит данные об одной книге.\n",
    "        Структура словаря соответствует возвращаемому значению get_book_data.\n",
    "    \"\"\"\n",
    "    all_books = []\n",
    "    book_urls = []\n",
    "    page_number = 1\n",
    "    \n",
    "    # Собираем все URL книг без прогресс-бара\n",
    "    while True:\n",
    "        try:\n",
    "            if page_number == 1:\n",
    "                url = \"http://books.toscrape.com/index.html\"\n",
    "            else:\n",
    "                url = f\"http://books.toscrape.com/catalogue/page-{page_number}.html\"\n",
    "\n",
    "            response = requests.get(url, timeout=10)\n",
    "            if response.status_code == 404:\n",
    "                break\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            books = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "            if not books:\n",
    "                break\n",
    "\n",
    "            # Собираем URL книг с текущей страницы\n",
    "            for book in books:\n",
    "                link_tag = book.find('h3').find('a')\n",
    "                if link_tag:\n",
    "                    link = link_tag['href']\n",
    "                    if link.startswith('../../../'):\n",
    "                        full_url = link.replace('../../../', 'http://books.toscrape.com/catalogue/')\n",
    "                    elif link.startswith('../'):\n",
    "                        full_url = link.replace('../', 'http://books.toscrape.com/catalogue/')\n",
    "                    elif link.startswith('catalogue/'):\n",
    "                        full_url = 'http://books.toscrape.com/' + link\n",
    "                    else:\n",
    "                        full_url = 'http://books.toscrape.com/catalogue/' + link\n",
    "                    book_urls.append(full_url)\n",
    "\n",
    "            # Проверяем есть ли следующая страница\n",
    "            next_button = soup.find('li', class_='next')\n",
    "            if not next_button:\n",
    "                break\n",
    "\n",
    "            page_number += 1\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при поиске страниц: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Всего найдено книг: {len(book_urls)}\")\n",
    "    \n",
    "\n",
    "    with tqdm(total=len(book_urls), desc=\"Обработка книг\", unit=\"книга\") as pbar:\n",
    "        for book_url in book_urls:\n",
    "            try:\n",
    "                book_info = get_book_data(book_url)\n",
    "                all_books.append(book_info)\n",
    "                pbar.set_postfix(book=book_info['title'][:20])\n",
    "                time.sleep(0.1)\n",
    "            except Exception as e:\n",
    "                pbar.set_postfix(error=\"Ошибка\")\n",
    "            finally:\n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Сохраняем в файл \n",
    "    if is_save and all_books:\n",
    "        try:\n",
    "            with open('books_data.txt', 'w', encoding='utf-8') as f:\n",
    "                for i, (book_url, book) in enumerate(zip(book_urls, all_books), 1):\n",
    "                    f.write(f\"URL: {book_url}\\n\")\n",
    "                    f.write(str(book))\n",
    "                    \n",
    "            print(f\"Сохранено {len(all_books)} книг в файл books_data.txt\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при сохранении: {e}\")\n",
    "    elif is_save:\n",
    "        print(\"Нет данных для сохранения\")\n",
    "    \n",
    "    print(f\"Обработано книг: {len(all_books)}\")\n",
    "    return all_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Bt7mrXcbkj5Q",
   "metadata": {
    "id": "Bt7mrXcbkj5Q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего найдено книг: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка книг: 100%|█████████████████████████████████| 1000/1000 [07:11<00:00,  2.32книга/s, book=1,000 Places to See]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранено 1000 книг в файл books_data.txt\n",
      "Обработано книг: 1000\n",
      "<class 'list'> 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверка работоспособности функции\n",
    "res = scrape_books(is_save=True) # Допишите ваши аргументы\n",
    "print(type(res), len(res)) # и проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z5fd728nl8a8",
   "metadata": {
    "id": "z5fd728nl8a8"
   },
   "source": [
    "## Задание 3. Настройка регулярной выгрузки (10 баллов)\n",
    "\n",
    "Настройте автоматический запуск функции сбора данных каждый день в 19:00.\n",
    "Для автоматизации используйте библиотеку `schedule`. Функция должна запускаться в указанное время и сохранять обновленные данные в текстовый файл.\n",
    "\n",
    "\n",
    "\n",
    "Бесконечный цикл должен обеспечивать постоянное ожидание времени для запуска задачи и выполнять ее по расписанию. Однако чтобы не перегружать систему, стоит подумать о том, чтобы выполнять проверку нужного времени не постоянно, а раз в какой-то промежуток. В этом вам может помочь `time.sleep(...)`.\n",
    "\n",
    "Проверьте работоспособность кода локально на любом времени чч:мм.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "SajRRCj4n8BZ",
   "metadata": {
    "id": "SajRRCj4n8BZ"
   },
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def schedule_scrape_books() -> None:\n",
    "    \"\"\"\n",
    "    Автоматически парсит книги со всех страниц сайта Books to Scrape.\n",
    "    Расписание:\n",
    "    - Основной запуск: ежедневно в 19:00\n",
    "    \"\"\"\n",
    "    # Настройка ежедневного автоматического парсинга в 19:00\n",
    "    schedule.every().day.at('19:00').do(scrape_books, is_save=True)\n",
    "\n",
    "    # Проверки выполнения запланированных задач (каждые 60 секунд)\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XFiPtEyaoLxq",
   "metadata": {
    "id": "XFiPtEyaoLxq"
   },
   "source": [
    "## Задание 4. Написание автотестов (15 баллов)\n",
    "\n",
    "Создайте минимум три автотеста для ключевых функций парсинга — например, `get_book_data` и `scrape_books`. Идеи проверок (можете использовать свои):\n",
    "\n",
    "* данные о книге возвращаются в виде словаря с нужными ключами;\n",
    "* список ссылок или количество собранных книг соответствует ожиданиям;\n",
    "* значения отдельных полей (например, `title`) корректны.\n",
    "\n",
    "Оформите тесты в отдельном скрипте `tests/test_scraper.py`, используйте библиотеку `pytest`. Убедитесь, что тесты проходят успешно при запуске из терминала командой `pytest`.\n",
    "\n",
    "Также выведите результат их выполнения в ячейке ниже.\n",
    "\n",
    "**Не забывайте про соблюдение PEP-8**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc641582",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25752/2060161589.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Добавляем путь к проекту\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'..'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscraper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_book_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from scraper import get_book_data, scrape_books\n",
    "\n",
    "\n",
    "class TestBookParser:\n",
    "    \"\"\"Тесты для функций парсинга книг\"\"\"\n",
    "\n",
    "    def test_get_book_data_returns_dict(self):\n",
    "        \"\"\"Тест: get_book_data возвращает словарь\"\"\"\n",
    "        # Используем реальный URL для тестирования\n",
    "        test_url = \"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\"\n",
    "        result = get_book_data(test_url)\n",
    "\n",
    "        assert isinstance(result, dict), \"Функция должна возвращать словарь\"\n",
    "\n",
    "    def test_get_book_data_has_required_keys(self):\n",
    "        \"\"\"Тест: словарь содержит все необходимые ключи\"\"\"\n",
    "        test_url = \"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\"\n",
    "        result = get_book_data(test_url)\n",
    "\n",
    "        required_keys = [\n",
    "            'title', 'price', 'rating', 'stock', 'description',\n",
    "            'upc', 'product_type', 'price_excl_tax', 'price_incl_tax',\n",
    "            'tax', 'availability', 'number_of_reviews'\n",
    "        ]\n",
    "\n",
    "        for key in required_keys:\n",
    "            assert key in result, f\"Отсутствует ключ: {key}\"\n",
    "\n",
    "    def test_get_book_data_title_not_empty(self):\n",
    "        \"\"\"Тест: название книги не пустое\"\"\"\n",
    "        test_url = \"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\"\n",
    "        result = get_book_data(test_url)\n",
    "\n",
    "        assert result['title'] != \"\", \"Название книги не должно быть пустым\"\n",
    "        assert len(result['title']) > 0, \"Название книги должно содержать текст\"\n",
    "        assert result['title'] != \"Нет названия\", \"Название должно быть получено\"\n",
    "\n",
    "    def test_scrape_books_returns_list(self):\n",
    "        \"\"\"Тест: scrape_books возвращает список\"\"\"\n",
    "        # Ограничиваем сбор 1 страницей для быстрого теста\n",
    "        result = scrape_books(is_save=False)\n",
    "\n",
    "        assert isinstance(result, list), \"Функция должна возвращать список\"\n",
    "\n",
    "    def test_scrape_books_contains_books(self):\n",
    "        \"\"\"Тест: scrape_books возвращает непустой список книг\"\"\"\n",
    "        result = scrape_books(is_save=False)\n",
    "\n",
    "        assert len(result) > 0, \"Список книг не должен быть пустым\"\n",
    "        assert all(isinstance(book, dict) for book in result), \"Все элементы должны быть словарями\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Запуск тестов вручную\n",
    "    test_class = TestBookParser()\n",
    "\n",
    "    print(\"ЗАПУСК АВТОТЕСТОВ\")\n",
    "\n",
    "    tests = [\n",
    "        (\"get_book_data возвращает словарь\", test_class.test_get_book_data_returns_dict),\n",
    "        (\"словарь содержит все необходимые ключи\", test_class.test_get_book_data_has_required_keys),\n",
    "        (\"название книги не пустое\", test_class.test_get_book_data_title_not_empty),\n",
    "        (\"scrape_books возвращает список\", test_class.test_scrape_books_returns_list),\n",
    "        (\"scrape_books возвращает непустой список книг\", test_class.test_scrape_books_contains_books),\n",
    "    ]\n",
    "\n",
    "    passed = 0\n",
    "    failed = 0\n",
    "\n",
    "    for test_name, test_func in tests:\n",
    "        try:\n",
    "            test_func()\n",
    "            print(f\"PASS: {test_name}\")\n",
    "            passed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"FAIL: {test_name}\")\n",
    "            print(f\"   Ошибка: {e}\")\n",
    "            failed += 1\n",
    "\n",
    "    print(f\"Результат: {passed} passed, {failed} failed\")\n",
    "\n",
    "    if failed == 0:\n",
    "        print(\"Все тесты прошли успешно!\")\n",
    "    else:\n",
    "        print(\"Некоторые тесты не прошли\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lBFAw4b3z8QY",
   "metadata": {
    "id": "lBFAw4b3z8QY",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.9.7, pytest-8.4.2, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\79688\n",
      "plugins: anyio-2.2.0\n",
      "collected 0 items\n",
      "\n",
      "============================== warnings summary ===============================\n",
      "D:\\Anaconda\\lib\\site-packages\\pyreadline\\py3k_compat.py:8\n",
      "  D:\\Anaconda\\lib\\site-packages\\pyreadline\\py3k_compat.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "    return isinstance(x, collections.Callable)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "============================= 1 warning in 0.09s ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: file or directory not found: test/test_scraper.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ячейка для демонстрации работоспособности\n",
    "# Сам код напишите в отдельном скрипте\n",
    "! pytest test/test_scraper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cRSQlHfRtOdN",
   "metadata": {
    "id": "cRSQlHfRtOdN"
   },
   "source": [
    "## Задание 5. Оформление проекта на GitHub и работа с Git (35 баллов)\n",
    "\n",
    "В этом задании нужно воспользоваться системой контроля версий Git и платформой GitHub для хранения и управления своим проектом. **Ссылку на свой репозиторий пришлите в форме для сдачи ответа.**\n",
    "\n",
    "### Пошаговая инструкция и задания\n",
    "\n",
    "**1. Установите Git на свой компьютер.**\n",
    "\n",
    "* Для Windows: [скачайте установщик](https://git-scm.com/downloads) и выполните установку.\n",
    "* Для macOS:\n",
    "\n",
    "  ```\n",
    "  brew install git\n",
    "  ```\n",
    "* Для Linux:\n",
    "\n",
    "  ```\n",
    "  sudo apt update\n",
    "  sudo apt install git\n",
    "  ```\n",
    "\n",
    "**2. Настройте имя пользователя и email.**\n",
    "\n",
    "Это нужно для подписи ваших коммитов, сделайте в терминале через `git config ...`.\n",
    "\n",
    "**3. Создайте аккаунт на GitHub**, если у вас его еще нет:\n",
    "[https://github.com](https://github.com)\n",
    "\n",
    "**4. Создайте новый репозиторий на GitHub:**\n",
    "\n",
    "* Найдите кнопку **New repository**.\n",
    "* Укажите название, краткое описание, выберите тип **Public** (чтобы мы могли проверить ДЗ).\n",
    "* Не ставьте галочку Initialize this repository with a README.\n",
    "\n",
    "**5. Создайте локальную папку с проектом.** Можно в терминале, можно через UI, это не имеет значения.\n",
    "\n",
    "**6. Инициализируйте Git в этой папке.** Здесь уже придется воспользоваться некоторой командой в терминале.\n",
    "\n",
    "**7. Привяжите локальный репозиторий к удаленному на GitHub.**\n",
    "\n",
    "**8. Создайте ветку разработки.** По умолчанию вы будете находиться в ветке `main`, создайте и переключитесь на ветку `hw-books-parser`.\n",
    "\n",
    "**9. Добавьте в проект следующие файлы и папки:**\n",
    "\n",
    "* `scraper.py` — ваш основной скрипт для сбора данных.\n",
    "* `README.md` — файл с кратким описанием проекта:\n",
    "\n",
    "  * цель;\n",
    "  * инструкции по запуску;\n",
    "  * список используемых библиотек.\n",
    "* `requirements.txt` — файл со списком зависимостей, необходимых для проекта (не присылайте все из глобального окружения, создайте изолированную виртуальную среду, добавьте в нее все нужное для проекта и получите список библиотек через `pip freeze`).\n",
    "* `artifacts/` — папка с результатами парсинга (`books_data.txt` — полностью или его часть, если весь не поместится на GitHub).\n",
    "* `notebooks/` — папка с заполненным ноутбуком `HW_03_python_ds_2025.ipynb` и запущенными ячейками с выводами на экран.\n",
    "* `tests/` — папка с тестами на `pytest`, оформите их в формате скрипта(-ов) с расширением `.py`.\n",
    "* `.gitignore` — стандартный файл, который позволит исключить временные файлы при добавлении в отслеживаемые (например, `__pycache__/`, `.DS_Store`, `*.pyc`, `venv/` и др.).\n",
    "\n",
    "\n",
    "**10. Сделайте коммит.**\n",
    "\n",
    "**11. Отправьте свою ветку на GitHub.**\n",
    "\n",
    "**12. Создайте Pull Request:**\n",
    "\n",
    "* Перейдите в репозиторий на GitHub.\n",
    "* Нажмите кнопку **Compare & pull request**.\n",
    "* Укажите, что было добавлено, и нажмите **Create pull request**.\n",
    "\n",
    "**13. Выполните слияние Pull Request:**\n",
    "\n",
    "* Убедитесь, что нет конфликтов.\n",
    "* Нажмите **Merge pull request**, затем **Confirm merge**.\n",
    "\n",
    "**14. Скачайте изменения из основной ветки локально.**\n",
    "\n",
    "\n",
    "\n",
    "### Требования к итоговому репозиторию\n",
    "\n",
    "* Файл `scraper.py` с рабочим кодом парсера.\n",
    "* `README.md` с описанием проекта и инструкцией по запуску.\n",
    "* Папка `artifacts/` с результатом сбора данных (`.txt` файл).\n",
    "* Папка `tests/` с тестами на `pytest`.\n",
    "* Папка `notebooks/` с заполненным ноутбуком `HW_03_python_ds_2025.ipynb`.\n",
    "* Pull Request с комментарием из ветки `hw-books-parser` в ветку `main`.\n",
    "* Примерная структура:\n",
    "\n",
    "  ```\n",
    "  books_scraper/\n",
    "  ├── artifacts/\n",
    "  │   └── books_data.txt\n",
    "  ├── notebooks/\n",
    "  │   └── HW_03_python_ds_2025.ipynb\n",
    "  ├── scraper.py\n",
    "  ├── README.md\n",
    "  ├── tests/\n",
    "  │   └── test_scraper.py\n",
    "  ├── .gitignore\n",
    "  └── requirements.txt\n",
    "  ```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
